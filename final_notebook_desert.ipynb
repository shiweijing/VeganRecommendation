{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Objective:__ Create a multiclass image classifier\n",
    "\n",
    "## __Purpose:__ Can be used to classify  species of animal\n",
    "\n",
    "### Use transfer learning and vgg16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools\n",
    "from tensorflow import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense  \n",
    "from tensorflow.keras import applications  \n",
    "from tensorflow.keras.utils import to_categorical  \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import math  \n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading up our image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default dimensions we found online\n",
    "img_width, img_height = 224, 224  \n",
    "   \n",
    "#Create a bottleneck file\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5' \n",
    "\n",
    "# loading up our datasets\n",
    "train_data_dir = 'data/train'  \n",
    "validation_data_dir = 'data/valid'  \n",
    "test_data_dir = 'data/test'\n",
    "   \n",
    "# number of epochs to train top model  \n",
    "epochs = 7 #this has been changed after multiple model run  \n",
    "# batch size used by flow_from_directory and predict_generator  \n",
    "batch_size = 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading vgc16 model\n",
    "vgg16 = applications.VGG16(include_top=False, weights=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)  #needed to create the bottleneck .npy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of weights/features with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2492 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
      "/opt/anaconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  0:05:40.891660\n"
     ]
    }
   ],
   "source": [
    "#__this can take an hour and half to run so only run it once. \n",
    "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "   \n",
    "generator = datagen.flow_from_directory(  \n",
    "     train_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=False)  \n",
    "   \n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)  \n",
    "   \n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_train = vgg16.predict_generator(generator, predict_size_train)  \n",
    "   \n",
    "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 images belonging to 2 classes.\n",
      "Time:  0:01:34.219910\n"
     ]
    }
   ],
   "source": [
    "#__this can take half an hour to run so only run it once. once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "generator = datagen.flow_from_directory(  \n",
    "     validation_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=False)  \n",
    "   \n",
    "nb_validation_samples = len(generator.filenames)  \n",
    "   \n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_validation = vgg16.predict_generator(  \n",
    "     generator, predict_size_validation)  \n",
    "   \n",
    "np.save('bottleneck_features_validation.npy', bottleneck_features_validation) \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 179 images belonging to 2 classes.\n",
      "Time:  0:00:24.876100\n"
     ]
    }
   ],
   "source": [
    "#__this can take half an hour to run so only run it once. once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "generator = datagen.flow_from_directory(  \n",
    "     test_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=False)  \n",
    "   \n",
    "nb_test_samples = len(generator.filenames)  \n",
    "   \n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_test = vgg16.predict_generator(  \n",
    "     generator, predict_size_test)  \n",
    "   \n",
    "np.save('bottleneck_features_test.npy', bottleneck_features_test) \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training, validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2492 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "         train_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode='categorical',  \n",
    "         shuffle=True)  \n",
    "   \n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "   \n",
    "# load the bottleneck features saved earlier  \n",
    "train_data = np.load('bottleneck_features_train.npy')  \n",
    "   \n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "   \n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list=train_labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 3.480e+02]\n",
      " [1.000e+00 2.144e+03]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(number_list, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation data\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "         validation_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode=None,  \n",
    "         shuffle=True)  \n",
    "   \n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "   \n",
    "validation_data = np.load('bottleneck_features_validation.npy')  \n",
    "   \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 179 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#testing data\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "         test_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode=None,  \n",
    "         shuffle=True)  \n",
    "   \n",
    "nb_test_samples = len(generator_top.filenames)  \n",
    "   \n",
    "test_data = np.load('bottleneck_features_test.npy')  \n",
    "   \n",
    "\n",
    "test_labels = generator_top.classes  \n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 4.,\n",
    "                1: 1.,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 2s 28ms/step - loss: 2.1675 - acc: 0.8188 - val_loss: 0.5465 - val_acc: 0.7896\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1s 16ms/step - loss: 1.3654 - acc: 0.8663 - val_loss: 0.5203 - val_acc: 0.7896\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.8581 - acc: 0.8621 - val_loss: 0.6056 - val_acc: 0.7896\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.6451 - acc: 0.8667 - val_loss: 0.6964 - val_acc: 0.7896\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.6000 - acc: 0.8689 - val_loss: 0.7239 - val_acc: 0.7896\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 1s 15ms/step - loss: 0.6391 - acc: 0.8548 - val_loss: 0.7366 - val_acc: 0.7896\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.6098 - acc: 0.8645 - val_loss: 0.7313 - val_acc: 0.7896\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.6108 - acc: 0.8610 - val_loss: 0.7308 - val_acc: 0.7896\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.6111 - acc: 0.8611 - val_loss: 0.7218 - val_acc: 0.7896\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.6217 - acc: 0.8597 - val_loss: 0.7274 - val_acc: 0.7896\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7274 - acc: 0.7896\n",
      "[INFO] accuracy: 78.96%\n",
      "[INFO] Loss: 0.72744220495224\n",
      "Time:  0:00:10.436392\n"
     ]
    }
   ],
   "source": [
    "#This is the best model we found. For additional models, check out I_notebook.ipynb\n",
    "start = datetime.datetime.now()\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3)))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3)))  \n",
    "model.add(Dropout(0.3)) \n",
    "\n",
    "model.add(Dense(num_classes, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])  \n",
    "\n",
    "history = model.fit(train_data, train_labels,  \n",
    "      epochs=10,\n",
    "      batch_size=batch_size,  \n",
    "      validation_data=(validation_data, validation_labels),class_weight=class_weight)  \n",
    "\n",
    "model.save_weights(top_model_weights_path)  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(  \n",
    " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))  \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6128 - acc: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6128278374671936, 0.832402229309082]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data [[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.31391788e-01 0.00000000e+00]\n",
      "   [1.21679522e-01 0.00000000e+00 1.97928452e+00 ... 0.00000000e+00\n",
      "    6.63630843e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.79248476e+00 ... 0.00000000e+00\n",
      "    1.39830983e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.10616398e+00 0.00000000e+00]\n",
      "   [1.28015727e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.76013350e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.58324897e-01 ... 0.00000000e+00\n",
      "    3.62342596e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 4.56636071e-01 1.62325525e+00 ... 3.34556997e-02\n",
      "    9.68558192e-02 0.00000000e+00]\n",
      "   [1.02060580e+00 0.00000000e+00 2.18553019e+00 ... 0.00000000e+00\n",
      "    7.10123539e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [8.36496711e-01 0.00000000e+00 1.50213623e+00 ... 0.00000000e+00\n",
      "    1.68040013e+00 0.00000000e+00]\n",
      "   [4.62967396e-01 0.00000000e+00 1.09279406e+00 ... 0.00000000e+00\n",
      "    1.48029053e+00 0.00000000e+00]\n",
      "   [1.44058213e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.00452459e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.92866135e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.27274847e+00 ... 0.00000000e+00\n",
      "    4.73324835e-01 0.00000000e+00]\n",
      "   [8.03788722e-01 0.00000000e+00 1.02501106e+00 ... 0.00000000e+00\n",
      "    9.40912485e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [1.05770659e+00 0.00000000e+00 5.54086506e-01 ... 0.00000000e+00\n",
      "    7.79936373e-01 0.00000000e+00]\n",
      "   [6.55032694e-01 0.00000000e+00 1.09626651e+00 ... 0.00000000e+00\n",
      "    9.53848124e-01 0.00000000e+00]\n",
      "   [1.72324747e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.76765352e-01 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.23042178e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.82802546e-01 ... 9.93437320e-02\n",
      "    1.17439699e+00 0.00000000e+00]\n",
      "   [2.86120981e-01 0.00000000e+00 5.94522059e-01 ... 0.00000000e+00\n",
      "    4.25562471e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [3.05723846e-02 0.00000000e+00 3.60984564e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.69922101e-01 0.00000000e+00 5.60989261e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.85538334e-01 0.00000000e+00 2.75252849e-01 ... 0.00000000e+00\n",
      "    3.84581566e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.82613152e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.18838465e-02 ... 0.00000000e+00\n",
      "    7.74125695e-01 0.00000000e+00]\n",
      "   [5.58477998e-01 0.00000000e+00 8.10374796e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [4.91030812e-01 0.00000000e+00 1.49482012e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.75683486e-01 0.00000000e+00 6.89981282e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.31229734e-01 0.00000000e+00 2.70969272e-01 ... 0.00000000e+00\n",
      "    3.44133794e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.59996998e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.79018426e-01 0.00000000e+00]\n",
      "   [4.76545423e-01 0.00000000e+00 6.97490096e-01 ... 0.00000000e+00\n",
      "    6.99861825e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [4.27980930e-01 0.00000000e+00 3.47446799e-02 ... 0.00000000e+00\n",
      "    6.51289225e-01 0.00000000e+00]\n",
      "   [8.60311627e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.32642651e+00 0.00000000e+00]\n",
      "   [8.62793505e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.19479728e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[5.57161719e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.99191046e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.71722460e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.37846804e-01 ... 0.00000000e+00\n",
      "    2.49855042e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 5.22177219e-01 ... 0.00000000e+00\n",
      "    6.99546576e-01 0.00000000e+00]\n",
      "   [6.55297279e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.03203928e+00 0.00000000e+00]\n",
      "   [1.03684521e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.39286542e+00 0.00000000e+00]]\n",
      "\n",
      "  [[6.89817131e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.41710830e-01 0.00000000e+00]\n",
      "   [9.41173077e-01 0.00000000e+00 3.68239194e-01 ... 0.00000000e+00\n",
      "    3.93404245e-01 0.00000000e+00]\n",
      "   [8.77581239e-01 0.00000000e+00 1.97738957e+00 ... 6.41673028e-01\n",
      "    1.47094429e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.71247506e+00 ... 2.84841657e-01\n",
      "    8.31739545e-01 0.00000000e+00]\n",
      "   [1.00687313e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.66974473e-01 0.00000000e+00]\n",
      "   [1.14122701e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.05840540e+00 0.00000000e+00]]\n",
      "\n",
      "  [[7.95238078e-01 0.00000000e+00 1.19723648e-01 ... 0.00000000e+00\n",
      "    5.41484952e-02 0.00000000e+00]\n",
      "   [1.06622028e+00 0.00000000e+00 1.70010042e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.32080936e-01 0.00000000e+00 1.59866142e+00 ... 1.11274749e-01\n",
      "    2.11608082e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [3.34844649e-01 0.00000000e+00 1.19478285e+00 ... 0.00000000e+00\n",
      "    3.11711878e-01 0.00000000e+00]\n",
      "   [1.19742715e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.12896740e-01 0.00000000e+00]\n",
      "   [7.21041262e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.82784796e-01 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.46031499e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.93544805e-01 0.00000000e+00]\n",
      "   [9.08604383e-01 0.00000000e+00 1.81228018e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.22175384e+00 0.00000000e+00 2.06295276e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [2.16249442e+00 0.00000000e+00 5.56900024e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [2.17309809e+00 0.00000000e+00 4.57464695e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.70359337e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.77499020e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.44262350e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.29711783e+00 0.00000000e+00 5.80686450e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [1.60777235e+00 0.00000000e+00 1.06817782e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.66911209e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.56561852e+00 0.00000000e+00 3.29663336e-01 ... 0.00000000e+00\n",
      "    2.43076205e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.21422982e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.12057471e-01 0.00000000e+00]\n",
      "   [3.59466314e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.37448931e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.81058335e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.18915200e-01 0.00000000e+00]\n",
      "   [4.98070329e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.02953076e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 1.12334144e+00 ... 0.00000000e+00\n",
      "    8.17805946e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.04065585e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.27714598e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.95343804e-01 0.00000000e+00]\n",
      "   [2.91469693e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.97187090e-01 0.00000000e+00]\n",
      "   [1.03228316e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.65068293e-01 0.00000000e+00]]\n",
      "\n",
      "  [[8.31167400e-01 0.00000000e+00 1.50749469e+00 ... 3.45005214e-01\n",
      "    9.53755736e-01 0.00000000e+00]\n",
      "   [5.57767630e-01 0.00000000e+00 1.39740670e+00 ... 5.04611850e-01\n",
      "    8.00123274e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 8.37194443e-01 ... 1.81306675e-02\n",
      "    1.11098731e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.48280191e+00 0.00000000e+00]\n",
      "   [5.66781521e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.40311074e+00 0.00000000e+00]\n",
      "   [5.61578870e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.60795522e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.22495246e+00 0.00000000e+00 4.97746468e-01 ... 0.00000000e+00\n",
      "    8.28656435e-01 0.00000000e+00]\n",
      "   [2.07355428e+00 0.00000000e+00 1.23750925e+00 ... 4.27346915e-01\n",
      "    4.87934947e-02 0.00000000e+00]\n",
      "   [1.14754701e+00 0.00000000e+00 9.39756513e-01 ... 0.00000000e+00\n",
      "    9.31459069e-02 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.89799637e-01 ... 8.45870376e-03\n",
      "    1.11919141e+00 0.00000000e+00]\n",
      "   [4.81984138e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.44590712e+00 0.00000000e+00]\n",
      "   [6.08078539e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.34335899e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.55574989e+00 0.00000000e+00]\n",
      "   [6.02391899e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.18058252e+00 0.00000000e+00]\n",
      "   [1.30361593e+00 0.00000000e+00 8.20689857e-01 ... 0.00000000e+00\n",
      "    3.18433046e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [2.31833982e+00 0.00000000e+00 9.48796570e-01 ... 2.25631803e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.78758740e-01 0.00000000e+00 5.01323402e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.55507290e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.43184566e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.99287653e+00 0.00000000e+00]\n",
      "   [1.18588924e+00 0.00000000e+00 1.36935830e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [1.55177474e+00 0.00000000e+00 1.13483059e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.10530651e+00 0.00000000e+00 3.87986541e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.12877607e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.72577000e+00 0.00000000e+00]\n",
      "   [7.09434822e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.32062387e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [7.17856228e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.40451312e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.43121552e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.62511587e-02 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.21290863e-01 ... 8.12860429e-02\n",
      "    1.66199625e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.20253086e+00 ... 7.57851750e-02\n",
      "    5.19947886e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 5.67606509e-01 ... 0.00000000e+00\n",
      "    6.86777949e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.19103110e-01 ... 0.00000000e+00\n",
      "    7.10996509e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.44641548e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.47124702e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.30144596e+00 ... 5.99139810e-01\n",
      "    2.39207745e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.58582664e+00 ... 4.62577641e-01\n",
      "    9.60985243e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [4.90698099e-01 0.00000000e+00 1.39210618e+00 ... 5.71972013e-01\n",
      "    8.14683437e-01 0.00000000e+00]\n",
      "   [4.19821143e-02 0.00000000e+00 1.40735936e+00 ... 7.80363679e-01\n",
      "    7.35554039e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.96141124e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.84932339e-01 0.00000000e+00]\n",
      "   [8.17817628e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.14039564e-01 0.00000000e+00]\n",
      "   [9.17114079e-01 0.00000000e+00 4.05565500e-01 ... 2.15843439e-01\n",
      "    8.20822239e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [7.04024374e-01 0.00000000e+00 7.75532067e-01 ... 1.20355248e-01\n",
      "    1.07313514e-01 0.00000000e+00]\n",
      "   [4.58408117e-01 0.00000000e+00 6.69971883e-01 ... 3.49012166e-01\n",
      "    1.29138231e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[3.75548542e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.37047780e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.80385458e-01 7.07781762e-02]\n",
      "   [1.90918997e-01 0.00000000e+00 1.41625226e-01 ... 1.60099491e-02\n",
      "    5.76009631e-01 1.17896423e-02]\n",
      "   ...\n",
      "   [2.44159132e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.09111249e-01 0.00000000e+00]\n",
      "   [3.76060694e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.44803464e-01 0.00000000e+00]\n",
      "   [1.94587946e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.09183908e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.68132973e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.62619829e-01 0.00000000e+00 1.93028212e+00 ... 5.40109754e-01\n",
      "    5.21315217e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [5.91985881e-01 0.00000000e+00 1.28987408e+00 ... 5.73007822e-01\n",
      "    7.26848662e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.20144725e+00 ... 6.19759262e-01\n",
      "    9.69015121e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.73887312e-01 0.00000000e+00]]\n",
      "\n",
      "  [[3.55517149e-01 0.00000000e+00 4.03024554e-02 ... 0.00000000e+00\n",
      "    3.01809400e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.65276909e+00 ... 0.00000000e+00\n",
      "    6.06290281e-01 0.00000000e+00]\n",
      "   [1.29711717e-01 0.00000000e+00 1.76146841e+00 ... 0.00000000e+00\n",
      "    6.76234841e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [6.53814912e-01 0.00000000e+00 1.12772107e+00 ... 4.72820312e-01\n",
      "    5.02190590e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.00892818e+00 ... 6.10673487e-01\n",
      "    5.29515624e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.74000549e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 1.42310292e-01 ... 0.00000000e+00\n",
      "    9.12082672e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.42261136e-01 ... 0.00000000e+00\n",
      "    9.81365860e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.09707487e-01 ... 0.00000000e+00\n",
      "    9.08083618e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 3.68879646e-01 ... 0.00000000e+00\n",
      "    2.46350914e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [2.77110994e-01 0.00000000e+00 4.02885079e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 5.15028238e-02 ... 0.00000000e+00\n",
      "    1.22648132e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.19141740e-01 ... 0.00000000e+00\n",
      "    9.60444808e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.10119712e-01 ... 0.00000000e+00\n",
      "    9.36869562e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 2.93433219e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.64663792e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.52591193e-01 0.00000000e+00]\n",
      "   [2.43491143e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.11966670e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    8.05949330e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.18495804e-01 ... 0.00000000e+00\n",
      "    3.67702007e-01 2.52131671e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.20783079e+00 ... 0.00000000e+00\n",
      "    5.50068676e-01 3.14804584e-01]\n",
      "   ...\n",
      "   [5.01449108e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.03461778e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.01458323e-01 0.00000000e+00]\n",
      "   [9.09762502e-01 0.00000000e+00 0.00000000e+00 ... 2.21113935e-02\n",
      "    2.41233766e-01 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.77099061e+00 ... 0.00000000e+00\n",
      "    3.44623208e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.71222234e+00 ... 3.89528424e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.24501562e+00 ... 5.82795203e-01\n",
      "    5.31070411e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 2.73739195e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [9.24904644e-02 0.00000000e+00 3.60695630e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.67828006e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 2.03233361e+00 ... 0.00000000e+00\n",
      "    9.81396794e-01 0.00000000e+00]\n",
      "   [6.98804855e-03 0.00000000e+00 2.70147443e+00 ... 2.98384249e-01\n",
      "    1.83869570e-01 0.00000000e+00]\n",
      "   [5.39113879e-01 0.00000000e+00 2.75657773e+00 ... 0.00000000e+00\n",
      "    3.58303696e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 2.01012468e+00 ... 1.76796496e-01\n",
      "    8.98459554e-02 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.86617410e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.48346663e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 6.14029467e-02 ... 0.00000000e+00\n",
      "    1.60589552e+00 0.00000000e+00]\n",
      "   [2.89108843e-01 0.00000000e+00 8.68424177e-01 ... 0.00000000e+00\n",
      "    1.53990722e+00 0.00000000e+00]\n",
      "   [4.29731995e-01 0.00000000e+00 1.94481325e+00 ... 0.00000000e+00\n",
      "    1.22450519e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.06327212e+00 ... 0.00000000e+00\n",
      "    1.16929722e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.28016734e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.76538181e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.39064336e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.20416743e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.41017532e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.95458460e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.56234384e-01 0.00000000e+00]\n",
      "   [2.08796591e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.45570529e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.44324672e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.44874871e-01 0.00000000e+00]\n",
      "   [1.79884136e-02 0.00000000e+00 7.62391090e-03 ... 5.60557991e-02\n",
      "    7.47810304e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.54654765e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.27766132e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.19399619e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 8.02894115e-01 ... 0.00000000e+00\n",
      "    7.26855814e-01 0.00000000e+00]\n",
      "   [5.37996292e-02 7.00234771e-02 1.34913766e+00 ... 3.73728275e-01\n",
      "    7.07088232e-01 0.00000000e+00]\n",
      "   [3.54612142e-01 0.00000000e+00 1.42814815e+00 ... 4.80058819e-01\n",
      "    9.06273961e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 1.85860705e+00 ... 0.00000000e+00\n",
      "    1.06414771e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.56375790e+00 ... 0.00000000e+00\n",
      "    5.94640315e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 1.87735200e-01 ... 0.00000000e+00\n",
      "    7.11762130e-01 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[5.58851123e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.28966832e+00 0.00000000e+00]\n",
      "   [5.01272500e-01 0.00000000e+00 2.76648492e-01 ... 0.00000000e+00\n",
      "    9.58689928e-01 0.00000000e+00]\n",
      "   [4.12633032e-01 0.00000000e+00 3.31813693e-01 ... 0.00000000e+00\n",
      "    1.96701080e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.23374605e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.29148448e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.32071948e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.20498109e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.34119499e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.10346004e-02\n",
      "    6.17905617e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.60381854e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.62344480e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    7.81069279e-01 0.00000000e+00]]\n",
      "\n",
      "  [[2.11841613e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.02968621e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.59214854e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    4.84980345e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.56794417e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.55674684e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.91254902e-01 0.00000000e+00]]]]\n",
      "rounded test_labels [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('test data', test_data)\n",
    "preds = np.round(model.predict(test_data),0) \n",
    "#to fit them into classification metrics and confusion metrics, some additional modificaitions are required\n",
    "print('rounded test_labels', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-vegan       0.85      1.00      0.92       150\n",
      "       vegan       1.00      0.10      0.18        30\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       180\n",
      "   macro avg       0.92      0.55      0.55       180\n",
      "weighted avg       0.87      0.85      0.79       180\n",
      " samples avg       0.85      0.85      0.85       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "animals = ['non-vegan', 'vegan']\n",
    "classification_metrics = metrics.classification_report(test_labels, preds, target_names=animals )\n",
    "print(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_test_labels = pd.DataFrame(test_labels).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(preds).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix= confusion_matrix(categorical_test_labels, categorical_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get better visual of the confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix, ['non-vegan', 'vegan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Those numbers are all over the place. Now turning normalize= True\n",
    "plot_confusion_matrix(confusion_matrix, \n",
    "                      ['non-vegan', 'vegan'],\n",
    "                     normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception = applications.Xception(include_top=False, weights='imagenet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a bottleneck file\n",
    "top_model_weights_path_xception = 'bottleneck_fc_model_xception.h5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2686 images belonging to 2 classes.\n",
      "Time:  0:03:11.232913\n"
     ]
    }
   ],
   "source": [
    "#__this can take an hour and half to run so only run it once. \n",
    "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "   \n",
    "generator = datagen.flow_from_directory(  \n",
    "     train_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=True)  \n",
    "   \n",
    "nb_train_samples = len(generator.filenames)  \n",
    "num_classes = len(generator.class_indices)  \n",
    "   \n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_train = xception.predict_generator(generator, predict_size_train)  \n",
    "   \n",
    "np.save('bottleneck_features_train_xception.npy', bottleneck_features_train)\n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 images belonging to 2 classes.\n",
      "Time:  0:00:42.587792\n"
     ]
    }
   ],
   "source": [
    "#__this can take half an hour to run so only run it once. once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "generator = datagen.flow_from_directory(  \n",
    "     validation_data_dir,  \n",
    "     target_size=(img_width, img_height),  \n",
    "     batch_size=batch_size,  \n",
    "     class_mode=None,  \n",
    "     shuffle=True)  \n",
    "   \n",
    "nb_validation_samples = len(generator.filenames)  \n",
    "   \n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))  \n",
    "   \n",
    "bottleneck_features_validation = xception.predict_generator(  \n",
    "     generator, predict_size_validation)  \n",
    "   \n",
    "np.save('bottleneck_features_validation_xception.npy', bottleneck_features_validation) \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2686 images belonging to 2 classes.\n",
      "Found 694 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "         train_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode='categorical',  \n",
    "         shuffle=True)  \n",
    "   \n",
    "nb_train_samples = len(generator_top.filenames)  \n",
    "num_classes = len(generator_top.class_indices)  \n",
    "   \n",
    "# load the bottleneck features saved earlier  \n",
    "train_data = np.load('bottleneck_features_train_xception.npy')  \n",
    "   \n",
    "# get the class lebels for the training data, in the original order  \n",
    "train_labels = generator_top.classes  \n",
    "   \n",
    "# convert the training labels to categorical vectors  \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes) \n",
    "\n",
    "#validation data\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "         validation_data_dir,  \n",
    "         target_size=(img_width, img_height),  \n",
    "         batch_size=batch_size,  \n",
    "         class_mode=None,  \n",
    "         shuffle=True)  \n",
    "   \n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "   \n",
    "validation_data = np.load('bottleneck_features_validation_xception.npy')  \n",
    "   \n",
    "\n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 5s 78ms/step - loss: 0.9244 - acc: 0.8110 - val_loss: 0.5937 - val_acc: 0.7896\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.5351 - acc: 0.8341 - val_loss: 0.6301 - val_acc: 0.7867\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.5432 - acc: 0.8249 - val_loss: 0.7740 - val_acc: 0.7896\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 4s 71ms/step - loss: 0.4885 - acc: 0.8534 - val_loss: 0.6645 - val_acc: 0.7781\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.4605 - acc: 0.8542 - val_loss: 0.8291 - val_acc: 0.7882\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.4882 - acc: 0.8422 - val_loss: 0.6808 - val_acc: 0.7608\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.4361 - acc: 0.8574 - val_loss: 0.7718 - val_acc: 0.6513\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.4821 - acc: 0.8496 - val_loss: 0.8827 - val_acc: 0.7219\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 0.3987 - acc: 0.8667 - val_loss: 0.8028 - val_acc: 0.7450\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.4103 - acc: 0.8702 - val_loss: 1.0782 - val_acc: 0.7853\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.4352 - acc: 0.8561 - val_loss: 1.0837 - val_acc: 0.7781\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.3646 - acc: 0.8784 - val_loss: 0.9919 - val_acc: 0.7795\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.3513 - acc: 0.8906 - val_loss: 1.1545 - val_acc: 0.7666\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.3123 - acc: 0.9018 - val_loss: 0.8853 - val_acc: 0.6599\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 0.3499 - acc: 0.8829 - val_loss: 0.9889 - val_acc: 0.6499\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 4s 67ms/step - loss: 0.3459 - acc: 0.8835 - val_loss: 1.3416 - val_acc: 0.7767\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 4s 78ms/step - loss: 0.3093 - acc: 0.8972 - val_loss: 1.0129 - val_acc: 0.7493\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.3097 - acc: 0.9028 - val_loss: 1.1928 - val_acc: 0.7767\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.3423 - acc: 0.8776 - val_loss: 1.2651 - val_acc: 0.7781\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.3283 - acc: 0.8851 - val_loss: 1.1259 - val_acc: 0.7493\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.1259 - acc: 0.7493\n",
      "[INFO] accuracy: 74.93%\n",
      "[INFO] Loss: 1.1259417533874512\n",
      "Time:  0:01:16.399310\n"
     ]
    }
   ],
   "source": [
    "#This is the best model we found. For additional models, check out I_notebook.ipynb\n",
    "start = datetime.datetime.now()\n",
    "model = Sequential()  \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3)))  \n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3)))  \n",
    "model.add(Dropout(0.3)) \n",
    "\n",
    "model.add(Dense(num_classes, activation='sigmoid'))  \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])  \n",
    "\n",
    "history = model.fit(train_data, train_labels,  \n",
    "      epochs=20,\n",
    "      batch_size=batch_size,  \n",
    "      validation_data=(validation_data, validation_labels))  \n",
    "\n",
    "model.save_weights(top_model_weights_path_xception)  \n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(  \n",
    " validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))  \n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))  \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
